apiVersion: v1
kind: Namespace
metadata:
  name: sml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: simple-torch-inference-bert
  namespace: sml
  labels:
    app: simple-torch-inference-bert
spec:
  selector:
    matchLabels:
      app: simple-torch-inference-bert
  template:
    metadata:
      labels:
        app: simple-torch-inference-bert
    spec:
      containers:
      - name: simple-torch-inference-bert
        image: tripabhi/simple-torch-inference-bert:1.0.0-wsgi
        ports:
        - containerPort: 9081
        resources:
          requests:
            cpu: 2000m
            memory: 3000Mi
          limits:
            memory: 4000Mi
---
apiVersion: v1
kind: Service
metadata:
  name: simple-torch-inference-bert
  namespace: sml
spec:
  selector:
    app: simple-torch-inference-bert
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9081
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: simple-torch-inference-bert-hpa
  namespace: sml
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: simple-torch-inference-bert
  minReplicas: 4
  maxReplicas: 16
  metrics:
    - type: Pods
      pods:
        metric:
          name: response_latency_ms_80th
        target:
          type: AverageValue
          averageValue: 800